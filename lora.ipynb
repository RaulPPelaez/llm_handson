{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8aa9e0bb-383d-47bb-852b-09e435500dae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "def display_chat(messages):\n",
    "    \"\"\"\n",
    "    Displays messages in a Jupyter Notebook using Markdown formatting.\n",
    "    Different roles ('system', 'user', 'assistant') are styled differently.\n",
    "    \"\"\"\n",
    "\n",
    "    markdown_output = \"\"\n",
    "\n",
    "    for message in messages:\n",
    "        role = message.get('role')\n",
    "        content = message.get('content').replace('\\n', '  \\n')\n",
    "        if role is None or content is None:\n",
    "            raise ValueError(\"Each message must have 'role' and 'content'.\")\n",
    "        if role == 'system':\n",
    "            markdown_output += f\"**System prompt:** {content}\\n\\n\"\n",
    "        elif role == 'user':\n",
    "            markdown_output += f\"ðŸ‘¤: {content}\\n\\n\"\n",
    "        elif role == 'assistant':\n",
    "            markdown_output += f\"ðŸ¤–: {content}\\n\\n\"\n",
    "        else:\n",
    "            markdown_output += f\"Unrecognized role:{role}\\n\\n\"\n",
    "\n",
    "    # Display formatted markdown\n",
    "    display(Markdown(markdown_output))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a812b402-17b6-4177-b1c7-00ea0dcad346",
   "metadata": {},
   "source": [
    "# (Q)LoRA finetuning  \n",
    "\n",
    "### Training <0.1% of the parameters  \n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af73a0-bad4-462d-b6aa-75adfb595c85",
   "metadata": {},
   "source": [
    "LoRA injects low rank linear layers (BA) into every linear layer in the architecture. QLoRA is just the addition of quantization to a LoRA model.\n",
    "\n",
    "Quantization allows to finetune a 7B model on a 4090 by reducing 4x the memory requirements.\n",
    "\n",
    "Quant reduces model performance, but LoRA is able to mitigate this while also finetuning the model on a downstream task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c016132-843b-4467-925c-f3b0a9197617",
   "metadata": {},
   "source": [
    "## Load the base model\n",
    "\n",
    "An already finetuned model can be finetuned further, but lets stick to a so-called pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc97afa4-4e43-4ee2-b7cb-50b7229654bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/raul/mambaforge/envs/llm_slides/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:32<00:00, 16.48s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "# Mistral is a base model, not finetuned for any specific task \n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, device_map=\"cuda:0\", torch_dtype=torch.bfloat16,  quantization_config=nf4_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a7be42-e7a6-4250-b77a-41ed2ac508e0",
   "metadata": {},
   "source": [
    "# Prepare a dataset\n",
    "Our example finetuning will perform a simple task using SMILES.\n",
    "For a given SMILES we will instruct the model to produce the same SMILE but reversed.\n",
    "\n",
    "I have prepared a dataset with some smiles and their reverses. So from `smile` I want to get `smile[::-1]`.\n",
    "\n",
    "Although this would be more fitting to a sequence to sequence model, we will encode this as a CausalLM task and finetune on it using next token prediction. The 7B model should be powerful enough to handle it anyhow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0b566663-5e3b-402e-b88d-2d85c6db57ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>rev_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C=CC(=O)N1C[C@@H]2CCOc3c(Cl)c(-c4c(O)cccc4F)c(F)c4ncnc(c34)N2C[C@H]1C</td>\n",
       "      <td>C1]H@C[C2N)43c(cncn4c)F(c)F4cccc)O(c4c-(c)lC(c3cOCC2]H@@C[C1N)O=(CC=C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COc1ccc2c(c1)OCc1c-2oc2ccccc2c1=O</td>\n",
       "      <td>O=1c2ccccc2co2-c1cCO)1c(c2ccc1cOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COc1ccc2c(c1)NC1=C(C(=O)OC1)C2c1cc(OC)c(OC)c(OC)c1</td>\n",
       "      <td>1c)CO(c)CO(c)CO(cc1c2C)1CO)O=(C(C=1CN)1c(c2ccc1cOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC[C@@]1(O)C[C@H](OC2CC(N(C)C)C(OC3CC(O)C(OC4CCC(=O)C(C)O4)C(C)O3)C(C)O2)c2c(cc3c(c2O)C(=O)c2c(O...</td>\n",
       "      <td>CO)O=(C1]H@C[)O=3C2cccc)O(c2c)O=(C)O2c(c3cc(c2c)2O)C(C)3O)C(C)4O)C(C)O=(CCC4CO(C)O(CC3CO(C)C)C(N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COc1ccc2c(c1)OC(N)=C(C#N)C2c1cc(OC)c(OC)c(OC)c1</td>\n",
       "      <td>1c)CO(c)CO(c)CO(cc1c2C)N#C(C=)N(CO)1c(c2ccc1cOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                smiles  \\\n",
       "0                                C=CC(=O)N1C[C@@H]2CCOc3c(Cl)c(-c4c(O)cccc4F)c(F)c4ncnc(c34)N2C[C@H]1C   \n",
       "1                                                                    COc1ccc2c(c1)OCc1c-2oc2ccccc2c1=O   \n",
       "2                                                   COc1ccc2c(c1)NC1=C(C(=O)OC1)C2c1cc(OC)c(OC)c(OC)c1   \n",
       "3  CC[C@@]1(O)C[C@H](OC2CC(N(C)C)C(OC3CC(O)C(OC4CCC(=O)C(C)O4)C(C)O3)C(C)O2)c2c(cc3c(c2O)C(=O)c2c(O...   \n",
       "4                                                      COc1ccc2c(c1)OC(N)=C(C#N)C2c1cc(OC)c(OC)c(OC)c1   \n",
       "\n",
       "                                                                                            rev_smiles  \n",
       "0                                C1]H@C[C2N)43c(cncn4c)F(c)F4cccc)O(c4c-(c)lC(c3cOCC2]H@@C[C1N)O=(CC=C  \n",
       "1                                                                    O=1c2ccccc2co2-c1cCO)1c(c2ccc1cOC  \n",
       "2                                                   1c)CO(c)CO(c)CO(cc1c2C)1CO)O=(C(C=1CN)1c(c2ccc1cOC  \n",
       "3  CO)O=(C1]H@C[)O=3C2cccc)O(c2c)O=(C)O2c(c3cc(c2c)2O)C(C)3O)C(C)4O)C(C)O=(CCC4CO(C)O(CC3CO(C)C)C(N...  \n",
       "4                                                      1c)CO(c)CO(c)CO(cc1c2C)N#C(C=)N(CO)1c(c2ccc1cOC  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dsp = pd.read_csv(\"small_smiles.csv\")\n",
    "dsp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d70d8-1c65-4271-a2b1-2287891107c8",
   "metadata": {},
   "source": [
    "We will create a dataset with labels so that for each `[SMILE]` and `[REV_SMILE]` pair we get:  \n",
    "`[SMILE]<reversed>[REV_SMILE]<end_of_smile>`  \n",
    "The tokenizer will prepend each sample with the special token `tokenizer.bos_token` (normally `<s>`) and will place `tokenizer.eos_token` at the end. However, adding our own special separator will help the model.\n",
    "\n",
    "#### I find that 6K examples are enough for the model to understand the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a3b9ecb1-a918-495e-8ca6-65b1ad6b8281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C=CC(=O)N1C[C@@H]2CCOc3c(Cl)c(-c4c(O)cccc4F)c(F)c4ncnc(c34)N2C[C@H]1C&lt;reversed&gt;C1]H@C[C2N)43c(cn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COc1ccc2c(c1)OCc1c-2oc2ccccc2c1=O&lt;reversed&gt;O=1c2ccccc2co2-c1cCO)1c(c2ccc1cOC&lt;end_of_smile&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COc1ccc2c(c1)NC1=C(C(=O)OC1)C2c1cc(OC)c(OC)c(OC)c1&lt;reversed&gt;1c)CO(c)CO(c)CO(cc1c2C)1CO)O=(C(C=1C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC[C@@]1(O)C[C@H](OC2CC(N(C)C)C(OC3CC(O)C(OC4CCC(=O)C(C)O4)C(C)O3)C(C)O2)c2c(cc3c(c2O)C(=O)c2c(O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COc1ccc2c(c1)OC(N)=C(C#N)C2c1cc(OC)c(OC)c(OC)c1&lt;reversed&gt;1c)CO(c)CO(c)CO(cc1c2C)N#C(C=)N(CO)1c(c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                labels\n",
       "0  C=CC(=O)N1C[C@@H]2CCOc3c(Cl)c(-c4c(O)cccc4F)c(F)c4ncnc(c34)N2C[C@H]1C<reversed>C1]H@C[C2N)43c(cn...\n",
       "1           COc1ccc2c(c1)OCc1c-2oc2ccccc2c1=O<reversed>O=1c2ccccc2co2-c1cCO)1c(c2ccc1cOC<end_of_smile>\n",
       "2  COc1ccc2c(c1)NC1=C(C(=O)OC1)C2c1cc(OC)c(OC)c(OC)c1<reversed>1c)CO(c)CO(c)CO(cc1c2C)1CO)O=(C(C=1C...\n",
       "3  CC[C@@]1(O)C[C@H](OC2CC(N(C)C)C(OC3CC(O)C(OC4CCC(=O)C(C)O4)C(C)O3)C(C)O2)c2c(cc3c(c2O)C(=O)c2c(O...\n",
       "4  COc1ccc2c(c1)OC(N)=C(C#N)C2c1cc(OC)c(OC)c(OC)c1<reversed>1c)CO(c)CO(c)CO(cc1c2C)N#C(C=)N(CO)1c(c..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset = 6000\n",
    "smile_separator = \"<reversed>\"\n",
    "smile_end = \"<end_of_smile>\"\n",
    "smiles = np.array([s+smile_separator+r+smile_end for s,r in zip(dsp[\"smiles\"][:subset], dsp[\"rev_smiles\"][:subset])])\n",
    "ds = pd.DataFrame.from_dict({\"labels\": smiles})\n",
    "display(ds.head())\n",
    "ds = datasets.Dataset.from_pandas(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55f9d0-7a8c-41d0-885c-70a6db214f86",
   "metadata": {},
   "source": [
    "The tokenizer of a model intended for conversation is not really fit for SMILES, so they will tend to be encoded as a really long series of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "821185ae-5871-4e95-927c-18c200b83e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "token_counts = [len(tokenizer.encode(text)) for text in smiles]\n",
    "plt.hist(token_counts, bins='auto', color='green', alpha=0.7)\n",
    "plt.title('Histogram of Token Counts')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cad1bca-53e7-40f9-82f2-34081e5c718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = ds.train_test_split(test_size=0.2)\n",
    "validation = train_test['test'].train_test_split(test_size=0.5)\n",
    "split_ds = {\n",
    "        'train': train_test['train'],\n",
    "        'validation': validation['train'],\n",
    "        'test': validation['test']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c8ec2e-39d0-4a70-8492-d38d94615c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['labels'],\n",
       "     num_rows: 2400\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['labels'],\n",
       "     num_rows: 300\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['labels'],\n",
       "     num_rows: 300\n",
       " })}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df0abe-ad83-4240-87bc-e072c6c20aa5",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "# Adding a LoRA adapter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b0a6f6-5889-4d07-8d9a-ccf672fc5fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836\n"
     ]
    }
   ],
   "source": [
    "import peft # Parameter Efficient Finetuning. Contains utilities for adding adapters to HF models\n",
    "lora_config = peft.LoraConfig(peft_type=peft.TaskType.CAUSAL_LM,\n",
    "                              inference_mode=False,\n",
    "                              r=8, # Rank\n",
    "                              lora_alpha=32,\n",
    "                              lora_dropout=0.1)\n",
    "model = peft.get_peft_model(model, lora_config)\n",
    "display(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f5874-20cc-48f3-83aa-eef6c8859150",
   "metadata": {},
   "source": [
    "### Inspecting the model reveals that LoRA has been hooked into some of the linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86d056a-2a30-42b6-aa62-f307eb0cc874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModel(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralAttention(\n",
      "              (q_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "              (v_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a0a35-e137-49c4-abde-f354e67033c3",
   "metadata": {},
   "source": [
    "# Finetuning with the transformers Supervised Finetuning Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b99033e-7c1f-4a44-a932-461ce3cdbaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4800/4800 [00:00<00:00, 5866.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,              \n",
    "    logging_steps=100,\n",
    "    logging_dir=\"./logs\",            \n",
    "    output_dir=\"./results\",         \n",
    "    learning_rate=2e-4,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=2000,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "tokenizer.padding_side = 'right'\n",
    "model = model.to(\"cuda\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_ds[\"train\"],\n",
    "    dataset_text_field=\"labels\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0de70cbd-d338-46be-8e4e-9cf6ca72ab9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 17:03, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.799900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.746700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.745200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.680300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.639300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.643200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.606300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.605600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.609900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.626800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.625400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.604300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.595200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.607400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.6674249382019043, metrics={'train_runtime': 1024.5176, 'train_samples_per_second': 1.952, 'train_steps_per_second': 1.952, 'total_flos': 9124603172708352.0, 'train_loss': 0.6674249382019043, 'epoch': 0.42})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78fb3cc-1e03-4147-928f-b6044d379162",
   "metadata": {},
   "source": [
    "# Testing the model\n",
    "\n",
    "Lets try and see how the model behaves for a task by picking a SMILE and asking for its reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a7cfe7f8-f29c-4f00-ba43-1b1a8190038f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**SMILE:** `Cc1cccc2c(N)c3cccc(C(=O)NCC[N+](C)(C)Cc4sc(N5CCOCC5)nc4[N+](=O)[O-])c3nc12`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Reverse:** `21cn3c)]-O[)O=(]+N[4cn)5CCOCC5N(cs4cC)C()C(]+N[CCN)O=(C(cccc3c)N(c2cccc1cC`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model input:**`Cc1cccc2c(N)c3cccc(C(=O)NCC[N+](C)(C)Cc4sc(N5CCOCC5)nc4[N+](=O)[O-])c3nc12<reversed>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=1\n",
    "smile = [s.split(smile_end)[0] for s in split_ds[\"test\"][i][\"labels\"].split(smile_separator)] \n",
    "tokens = tokenizer(smile[0]+smile_separator, return_tensors=\"pt\").to(\"cuda\")\n",
    "display(Markdown(f\"**SMILE:** `{smile[0]}`\"))\n",
    "display(Markdown(f\"**Reverse:** `{smile[1]}`\"))\n",
    "display(Markdown(f\"**Model input:**`{smile[0]+smile_separator}`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e06ea4-7551-43d1-947b-edbc55be0b6d",
   "metadata": {},
   "source": [
    "## First with the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7cc1655e-2b67-4b91-9647-300045ca5197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "### **Generated**\n",
       "------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "\n",
       "## Related Resources\n",
       "\n",
       "- ### 2019-2020 CAS Scholarship\n",
       "\n",
       "The CAS Scholarship is a merit-based scholarship for students who have demonstrated outstanding academic achievement and leadership.\n",
       "- ### 2019-2020 CAS Dean's Scholarship\n",
       "\n",
       "The```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "### **Truth**\n",
       "------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```21cn3c)]-O[)O=(]+N[4cn)5CCOCC5N(cs4cC)C()C(]+N[CCN)O=(C(cccc3c)N(c2cccc1cC```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with model.disable_adapter():\n",
    "   gen_tokens = model.generate(**tokens, max_new_tokens=len(smile[1]))[0]\n",
    "generated = tokenizer.decode(gen_tokens[tokens[\"input_ids\"].shape[1]:])\n",
    "display(Markdown(\"---\\n### **Generated**\\n------\"))\n",
    "display(Markdown(f\"```{generated.split(smile_end)[0]}```\"))\n",
    "display(Markdown(\"---\\n### **Truth**\\n------\"))\n",
    "display(Markdown(f\"```{smile[1]}```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1477806c-d905-4fdc-9d46-9cc54b34e7d7",
   "metadata": {},
   "source": [
    "## Now with the finetuned one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a471cb2-358e-4b2b-8ab5-5ef095f17aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### **Generated**\n",
       "------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```21cn3c)]-O[)O=(]+N[4cn)5CCOCC5N(cs4cC)C()C(]+N[CCN)O=(C(cccc3c)N(c2cccc1cC```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### **Truth**\n",
       "------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```21cn3c)]-O[)O=(]+N[4cn)5CCOCC5N(cs4cC)C()C(]+N[CCN)O=(C(cccc3c)N(c2cccc1cC```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_tokens = model.generate(**tokens, max_new_tokens=len(smile[1]))[0]\n",
    "generated = tokenizer.decode(gen_tokens[tokens[\"input_ids\"].shape[1]:])\n",
    "display(Markdown(\"### **Generated**\\n------\"))\n",
    "display(Markdown(f\"```{generated.split(smile_end)[0]}```\"))\n",
    "display(Markdown(\"### **Truth**\\n------\"))\n",
    "display(Markdown(f\"```{smile[1]}```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa8c8a-4242-4e5b-a0a1-e94c394fec3c",
   "metadata": {},
   "source": [
    "# Saving the adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8bb19002-77d3-49f4-a770-d86ab065ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"adapters/mistral_smiles_rev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1351e9-f73c-432e-ae21-fdca415dc4f3",
   "metadata": {},
   "source": [
    "### The information required to take this 15GB model from nonsense to SMILE reverser is just 14MB! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1ea77f51-458a-44ef-9610-45d8d5c8e9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14M\n",
      "8,0K -rw-r--r-- 1 raulp lab 5,9K nov 27 20:48 README.md\n",
      " 14M -rw-r--r-- 1 raulp lab  14M nov 27 20:48 adapter_model.bin\n",
      "4,0K -rw-r--r-- 1 raulp lab  600 nov 27 20:48 adapter_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lsrht adapters/mistral_smiles_rev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
